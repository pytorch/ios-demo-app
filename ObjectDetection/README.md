# Object Detection with YOLOv5 on iOS

## Introduction

[YOLO](https://pjreddie.com/darknet/yolo/) (You Only Look Once) is one of the fastest and most popular object detection models. [YOLOv5](https://github.com/ultralytics/yolov5) is an open-source implementation of the latest version of YOLO. This Object Detection with YOLOv5 iOS sample app uses the PyTorch scripted YOLOv5 model to detect objects of [80 classes](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml) trained with the model.

## Prerequisites

* PyTorch 1.7 or later (Optional)
* Python 3.8 (Optional)
* iOS Pytorch pod library 1.7
* Xcode 12 or later

## Quick Start

To Test Run the Object Detection iOS App, follow the steps below:

### 1. Prepare the Model

The Python script `export.py` in the `models` folder is used to generate a TorchScript-formatted YOLOv5 model named `yolov5s.torchscript.pt`  for mobile apps. If you don't have the PyTorch environment set up to run the script, you can download the model file [here](https://drive.google.com/file/d/15FFbi1ajWh02Dqc4W4HdGI45Th3VhbkR/view?usp=sharing) to the `ios-demo-app/ObjectDetection/ObjectDetection` folder.

Open a Mac Terminal, run the following commands:

```
git clone https://github.com/jeffxtang/yolov5
cd yolov5
pip install -r requirements.txt
```

Then edit `models/export.py` to make two changes:

* Change the line `model.model[-1].export = True` to `model.model[-1].export = False`

* Add the following two lines of model optimization code between `ts = torch.jit.trace(model, img)` and `ts.save(f)`:

```
    from torch.utils.mobile_optimizer import optimize_for_mobile
    ts = optimize_for_mobile(ts)
```

If you ignore this step, you can still create a TorchScript model for mobile apps to use, but the inference on a non-optimized model can take twice as long as the inference on an optimized model - using the iOS app test images, the average inference time on an optimized and non-optimized model is 0.6 seconds and 1.18 seconds, respectively. See [SCRIPT AND OPTIMIZE FOR MOBILE RECIPE](https://pytorch.org/tutorials/recipes/script_optimized.html) for more details.

Finally, run the script to generate the optimized TorchScript model:

```
python models/export.py
```

Note that small sized version of the YOLOv5 model, which runs faster but with less accuracy, is generated by default when running the `export.py`. You can also change the value of the `weights` parameter in the `export.py` to generate the medium, large, and extra large version of the model.

### 2. Use LibTorch

Run the commands below:

```
pod install
open ObjectDetection.xcworkspace/
```

### 3. Run the app
Select an iOS simulator or device on Xcode to run the app. Some example results are as follows:

results are:

![](screenshot1.png)
![](screenshot2.png)

![](screenshot3.png)
![](screenshot4.png)


You can also select a picture from your iOS device's Photos library or take a picture with the device camera and then do the object detection.
